{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f069cc",
   "metadata": {},
   "source": [
    "# Langchain Message Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9332a5",
   "metadata": {},
   "source": [
    "| Message Type  | Has `content` | Has `tool_calls` | Has `tool_call_id` |\n",
    "| ------------- | ------------- | ---------------- | ------------------ |\n",
    "| HumanMessage  | ✅             | ❌                | ❌                  |\n",
    "| AIMessage     | ✅             | ✅                | ❌                  |\n",
    "| ToolMessage   | ✅             | ❌                | ✅                  |\n",
    "| SystemMessage | ✅             | ❌                | ❌                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9375eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "@tool \n",
    "def add_func(a: int, b: int) -> int: \n",
    "    \"\"\"This function adds two numbers together and returns the final value\"\"\"\n",
    "    return a + b\n",
    "\n",
    "my_tools = [add_func]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools(my_tools)\n",
    "\n",
    "result = llm.invoke([HumanMessage(content=\"What is 5 plus 2\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749bad9",
   "metadata": {},
   "source": [
    "Phase 1 - When the LLM decides a tool should run, it returns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d58fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"add_func\",\n",
    "            \"args\": {\"a\": 5, \"b\": 2},\n",
    "            \"id\": \"call_abc123\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af09b2f",
   "metadata": {},
   "source": [
    "Phase 2 - LangGraph then executes the tool node, and produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToolMessage(\n",
    "    content=\"7\",\n",
    "    tool_call_id=\"call_abc123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9b428",
   "metadata": {},
   "source": [
    "Phase 3 - Now the LLM is invoked again with:\n",
    "- The original HumanMessage\n",
    "- The AI tool request\n",
    "- The ToolMessage result\n",
    "\n",
    "The model now responds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c701d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIMessage(\n",
    "    content=\"The result of 3 + 4 is 7.\",\n",
    "    tool_calls=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5c0d8",
   "metadata": {},
   "source": [
    "Some common attributes we check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa42dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8cd8007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add_func',\n",
       "  'args': {'a': 5, 'b': 2},\n",
       "  'id': 'call_f65eod8QCEHWRRrHLx4VDBen',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3edf62f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 18,\n",
       "  'prompt_tokens': 60,\n",
       "  'total_tokens': 78,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_af17f56e76',\n",
       " 'id': 'chatcmpl-D9DaO34uVdgIfJlxJvlH0UQhuccUX',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'tool_calls',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
